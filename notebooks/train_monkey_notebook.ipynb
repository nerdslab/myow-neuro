{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from myow import MLP, MYOW, MLP3\n",
    "from myow.data import MonkeyReachNeuralDataset\n",
    "from myow.transforms import get_neural_transform\n",
    "from myow.samplers import RelativeSequenceDataLoader\n",
    "from myow.utils import seed_everything, collect_params\n",
    "from myow.tasks.train_reach_angle_regressor import linear_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed = None\n",
    "seed_everything(seed=seed)\n",
    "\n",
    "# get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Using {device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare dataset\n",
    "\n",
    "The datasets were collected from two macaques, in Lee Miller lab at Northwestern U, as described in DAD paper [[1]](#1).\n",
    "Data collection was made over two days for each individual, the list of datasets can be found in the table below:\n",
    "\n",
    "| Primate | Day        | Day index | # of trials | # of neurons |\n",
    "|---------|------------|:---------:|:-----------:|:------------:|\n",
    "| Mihi    | 03/03/2014 |     1     |     209     |      187     |\n",
    "| Mihi    | 03/06/2014 |     2     |     215     |      172     |\n",
    "| Chewie  | 10/03/2013 |     1     |     159     |      174     |\n",
    "| Chewie  | 12/19/2013 |     2     |     180     |      155     |\n",
    "\n",
    "Neural activity is recorded in the primary motor cortex (M1), for which we have the corresponding reach direction (one of eight). All neural data are binned using 100ms windows.\n",
    "\n",
    "<a id=\"1\">[1]</a>\n",
    "Dyer, E.L., Gheshlaghi Azar, M., Perich, M.G. et al.\n",
    "A cryptography-based approach for movement decoding.\n",
    "Nat Biomed Eng 1, 967â€“976 (2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root = '../data/mihi-chewie'  # path to data\n",
    "primate = 'chewie' # options: 'chewie', 'mihi'\n",
    "day = 1 # options: 1, 2\n",
    "\n",
    "# load dataset for ssl (pre-train)\n",
    "dataset = MonkeyReachNeuralDataset(root, primate=primate, day=day, split='trainval')\n",
    "\n",
    "# prepare datasets for linear eval\n",
    "train_dataset = MonkeyReachNeuralDataset(root, primate=primate, day=day, split='train')\n",
    "val_dataset = MonkeyReachNeuralDataset(root, primate=primate, day=day, split='val')\n",
    "test_dataset = MonkeyReachNeuralDataset(root, primate=primate, day=day, split='test')\n",
    "\n",
    "# prepare dataset for visualization\n",
    "full_dataset = MonkeyReachNeuralDataset(root, primate=primate, day=day, split=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[6, 174], edge_index=[2, 5], y=[6], pos=[6, 2], vel=[6, 2], acc=[6, 2], force=[6, 2], timestep=[6])\n"
     ]
    }
   ],
   "source": [
    "print(full_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare data transforms\n",
    "We apply three transformations to the neural data:\n",
    "- **Randomized Dropout:** sets the firing rate of a random subset of neurons to zero. The dropout rate is uniformly sampled between `0` and `dropout_p`.\n",
    "- **Noise:** adds gaussian noise with standard deviation `noise_sigma` before normalization.\n",
    "- **Pepper or sparse additive noise:** increases the firing rate of a neuron by a constant `pepper_sigma` with a probability `pepper_p`.\n",
    "\n",
    "These transformations are not always applied, they are random, each applied with a probability of `[]_apply_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "dropout_p = 0.2 \n",
    "dropout_apply_p = 1.0\n",
    "\n",
    "# noise\n",
    "noise_sigma = 1.5\n",
    "noise_apply_p = 1.0\n",
    "\n",
    "# pepper\n",
    "pepper_p = 0.3 \n",
    "pepper_sigma = 1.5 \n",
    "pepper_apply_p = 0.5\n",
    "\n",
    "# get mean and std for normalization\n",
    "fr_mean, fr_std = dataset.get_mean_std('firing_rates')\n",
    "\n",
    "# get transforms\n",
    "transform = get_neural_transform(\n",
    "    randomized_dropout=dict(p=dropout_p, apply_p=dropout_apply_p),\n",
    "    pepper=dict(p=pepper_p, c=pepper_sigma, apply_p=pepper_apply_p),\n",
    "    noise=dict(std=noise_sigma, apply_p=noise_apply_p),\n",
    "    normalize=dict(mean=fr_mean, std=fr_std),\n",
    ")\n",
    "\n",
    "normalize = get_neural_transform(normalize=dict(mean=fr_mean, std=fr_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In addition to these neural augmentations, we use **Temporal jitter** where temporally neighboring samples are considered to be positive examples for one another. `max_lookahead` defines the positivity range. \n",
    "\n",
    "Here we set `max_lookahead = 2`, which means that samples `t-2` to `t+2` are positive views of `t`.\n",
    "`100ms` is our unit of time since we used it for binning.\n",
    "\n",
    "`RelativeSequenceDataLoader` is a custom dataloader that handles building positive views as well as the pool of candidates for view mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_lookahead = 2 \n",
    "batch_size = 512 \n",
    "\n",
    "dataloader = RelativeSequenceDataLoader(dataset, batch_size=batch_size, drop_last=True, shuffle=True,\n",
    "                                        transform=transform, pos_kmin=0, pos_kmax=max_lookahead,\n",
    "                                        num_workers=4, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The input is the firing rates vector for neurons. We use a Multi-layer perceptron (MLP) with batch normalization layers and ReLU activation as the encoder/feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hidden_layers = [64, 64, 64]\n",
    "representation_size = 64 # output representation size\n",
    "\n",
    "input_size = (fr_std != 0).sum() # some neurons never fire, we filter them out\n",
    "encoder = MLP([input_size, *hidden_layers, representation_size], batchnorm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmented and mined views are aligned in two different spaces, hence the use of two different pairs of projector/predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define number of nearest neighbors used during mining\n",
    "knn_nneighs = 5\n",
    "\n",
    "# define projector architecture\n",
    "projector_hidden_size = 256 # Hidden size of projectors\n",
    "projector_output_size = 32 # Output size of projectors\n",
    "\n",
    "# create projectors and predictors\n",
    "projector = nn.Identity()\n",
    "projector_m = MLP3(representation_size, projector_output_size, hidden_size=projector_hidden_size)\n",
    "predictor = MLP3(representation_size, representation_size, hidden_size=projector_hidden_size)  # used to predict across augmented views\n",
    "predictor_m = MLP3(projector_output_size, projector_output_size, hidden_size=projector_hidden_size)  # used to predict across mined views\n",
    "\n",
    "# make MYOW\n",
    "model = MYOW(encoder, projector, projector_m, predictor, predictor_m, layout='cascaded')\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During mining, the mined view is randomly sampled from the top-k nearest neighbors (`knn_nneighs`) of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of nearest neighbors used during mining\n",
    "knn_nneighs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we use different schedulers for our hyperparameters:\n",
    "- **learning rate**: After a linear warmup period of 100 epochs, the learning rate is decayed following a cosine decay scheduler.\n",
    "- **exponential moving average parameter**: $\\tau$ is decayed from 0.98 to 1, following a cosine decay scheduler. The target network is updated as an exponential moving average of the online network: target $\\leftarrow$ $\\tau$  target + (1 - $\\tau$) online\n",
    "- **loss weights**: early in training, the representation is still forming, we use an initial linear warmup period of a few epochs (10) where the mined loss term's contribution is small. The total loss is $(1 - \\lambda) \\textrm{loss}_{aug} +  \\lambda \\textrm{loss}_{mined}$\n",
    "\n",
    "Note that these curves are logged to TensorBoard, under the `SCALARS` tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "# compute total number of gradient steps\n",
    "num_steps_per_epoch = dataloader.num_examples // batch_size\n",
    "total_steps = num_steps_per_epoch * num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002 # base learning rate\n",
    "lr_warmup_epochs = 100\n",
    "lr_warmup_steps = num_steps_per_epoch * lr_warmup_epochs\n",
    "\n",
    "def update_learning_rate(step, max_val=lr, total_steps=total_steps, warmup_steps=lr_warmup_steps):\n",
    "    if 0 <= step <= warmup_steps:\n",
    "        return max_val * step / warmup_steps + 1e-9\n",
    "    else:\n",
    "        return max_val * (1 + np.cos((step - warmup_steps) * np.pi / (total_steps - warmup_steps))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = 0.98 # base momentum for moving average\n",
    "\n",
    "def update_momentum(step, max_val=mm, total_steps=total_steps):\n",
    "    return 1 - max_val * (1 + np.cos(step * np.pi / total_steps)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mined_weight = 0.5 # base loss weight for mined term\n",
    "mined_weight_warmup_epochs = 10 # warmup period\n",
    "mined_weight_warmup_steps = num_steps_per_epoch * mined_weight_warmup_epochs\n",
    "\n",
    "def update_weight(step, max_val=mined_weight, warmup_steps=mined_weight_warmup_steps):\n",
    "    if 0 <= step <= warmup_steps:\n",
    "        return max_val * step / warmup_steps + 1e-9\n",
    "    else:\n",
    "        return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "weight_decay = 2e-5 \n",
    "params = collect_params(model.trainable_modules, exclude_bias_and_bn=False)\n",
    "optimizer = torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tensorboard writer\n",
    "logdir = None # where the logs are stored\n",
    "writer = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(step):\n",
    "    for inputs in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # update params\n",
    "        lr = update_learning_rate(step)\n",
    "        mm = update_momentum(step)\n",
    "        weight = update_weight(step)\n",
    "\n",
    "        data = inputs['data'].to(device)\n",
    "        out = model(online_view=data, target_view=data)\n",
    "        \n",
    "        view_2 = inputs['view_2'].to(device)\n",
    "        out_2 = model(online_view=view_2, target_view=view_2)\n",
    "\n",
    "        # Augmented Views\n",
    "        view_1_index = inputs['view_1_index'].to(device)\n",
    "        online_q, target_z = out.online.q[view_1_index], out_2.target.z\n",
    "\n",
    "        # Augmented Views (Symmetric)\n",
    "        online_q_s, target_z_s = out_2.online.q, out.target.z[view_1_index]\n",
    "\n",
    "        # Mining\n",
    "        online_y, target_candidate_y = out.online.y, out.target.y\n",
    "        online_y = online_y[view_1_index]\n",
    "\n",
    "        # Compute cosine distance\n",
    "        online_y = F.normalize(online_y, dim=-1, p=2)\n",
    "        target_candidate_y = F.normalize(target_candidate_y, dim=-1, p=2)\n",
    "        dist = - torch.einsum('nc,kc->nk', [online_y, target_candidate_y])\n",
    "\n",
    "        # remove ineligible candidates\n",
    "        row, col = inputs['ccand_edge_index'].to(device)\n",
    "        n_mask = torch.unique(row)\n",
    "        n_idx = torch.zeros(target_candidate_y.size(0), dtype=torch.long)\n",
    "        n_idx[n_mask] = torch.arange(n_mask.size(0))\n",
    "        dist[n_idx[row], col] = torch.finfo(dist.dtype).max\n",
    "\n",
    "        # get k nearest neighbors\n",
    "        _, topk_index = torch.topk(dist, k=knn_nneighs, largest=False)\n",
    "\n",
    "        # randomly select mined view out the k nearest neighbors\n",
    "        mined_view_id = topk_index[torch.arange(topk_index.size(0), dtype=torch.long, device=dist.device),\n",
    "                                   torch.randint(knn_nneighs, size=(topk_index.size(0),))]\n",
    "\n",
    "        # Mined views\n",
    "        online_q_m = out.online.q_m[view_1_index]\n",
    "        target_v = out.target.v[mined_view_id]\n",
    "\n",
    "        # loss\n",
    "        aug_loss = 1 - 0.5 * cosine_similarity(online_q, target_z.detach(), dim=-1).mean() \\\n",
    "                   - 0.5 * cosine_similarity(online_q_s, target_z_s.detach(), dim=-1).mean()\n",
    "        mined_loss = 1 - cosine_similarity(online_q_m, target_v.detach(), dim=-1).mean()\n",
    "\n",
    "        loss = (1 - weight) * aug_loss + weight * mined_loss\n",
    "\n",
    "        loss.backward()\n",
    "        # update online network\n",
    "        optimizer.step()\n",
    "        # update target network\n",
    "        model.update_target_network(mm)\n",
    "\n",
    "        # log scalars\n",
    "        if step % 50 == 0:\n",
    "            writer.add_scalar('params/lr', lr, step)\n",
    "            writer.add_scalar('params/mm', mm, step)\n",
    "            writer.add_scalar('params/weight', weight, step)\n",
    "            writer.add_scalar('train/loss', loss, step)\n",
    "            writer.add_scalar('train/aug_loss', aug_loss, step)\n",
    "            writer.add_scalar('train/mined_loss', mined_loss, step)\n",
    "\n",
    "        step += 1\n",
    "    return step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Linear evaluation is performed every `linear_eval_epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "linear_eval_epochs = 10000\n",
    "\n",
    "def test(step):\n",
    "    encoder = copy.deepcopy(model.online_encoder.eval())\n",
    "    test_acc, test_delta_acc = linear_evaluate(encoder, train_dataset, val_dataset, test_dataset, normalize, writer, device, epoch)\n",
    "    return test_acc, test_delta_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    step = train(step)\n",
    "    if epoch % linear_eval_epochs == 0:\n",
    "        test_acc, test_delta_acc = test(step)\n",
    "\n",
    "print('Accuracy: %.2f\\nDelta-Accuracy: %.2f' % (100*test_acc, 100*test_delta_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing learned representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(step):\n",
    "    encoder = copy.deepcopy(model.online_encoder.eval())\n",
    "    # prepare data\n",
    "    x = normalize(full_dataset.x).to(device)\n",
    "\n",
    "    # compute representations\n",
    "    x = x.to(device)\n",
    "    with torch.inference_mode():\n",
    "        representations = encoder(x).to('cpu')\n",
    "\n",
    "    # get metadata\n",
    "    reach_direction = full_dataset.y.numpy()\n",
    "    timestep = full_dataset.timestep.numpy()\n",
    "    trial = full_dataset.batch.numpy()\n",
    "    vel = torch.norm(full_dataset.vel, 2, dim=1).numpy()\n",
    "\n",
    "    # get __seq_next__ to display trajectory\n",
    "    seq_next = np.zeros(full_dataset.num_samples, dtype='U8')\n",
    "    seq_next[full_dataset.edge_index[0]] = full_dataset.edge_index[1].numpy().astype('U8')\n",
    "\n",
    "    # combine metadata\n",
    "    metadata = np.column_stack([reach_direction, timestep, trial, vel, seq_next]).tolist()\n",
    "    metadata_header = ['reach_direction', 'timestep', 'trial_id', 'velocity', '__seq_next__']\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_embedding(representations, metadata=metadata, metadata_header=metadata_header, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned embeddings are saved to the embedding directory and can be viewed through TensorBoard's embedding projector. \n",
    "In tensorboard, go to the `PROJECTOR` tab (can be found in the dropdown menu).\n",
    "\n",
    "This is an example of what to expect. We use T-SNE with perplexity of 80, which highlights the global structure of the data.\n",
    "![](../docs/embedding_projector_screenshot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ecf3cdc332dee42c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ecf3cdc332dee42c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}